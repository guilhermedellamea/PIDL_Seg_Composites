{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import torch\n",
    "from data.datasets_pytorch import get_dataloaders\n",
    "from networks.UNetPytorch import UNet\n",
    "from tools import set_device\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "sns.set_style(\"white\")\n",
    "\n",
    "# Loading train/validation/test data\n",
    "with open(f\"./data/dataset.pkl\", \"rb\") as file:\n",
    "    dict_data = pickle.load(file)\n",
    "\n",
    "# Set device\n",
    "device = set_device()\n",
    "\n",
    "# Get Pytorch DataLoaders\n",
    "dataloaders = get_dataloaders(\n",
    "    dict_data,\n",
    "    device=device,\n",
    "    batch_size_train=16,\n",
    "    batch_size_validation=2,\n",
    "    num_workers=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nseg = UNet(\n",
    "    n_channels=1,\n",
    "    n_output_channels=3,\n",
    "    initial_channels=16,\n",
    "    ndepth=5,\n",
    "    bilinear=False,\n",
    "    activation=\"relu\",\n",
    "    dropout_rate=0.1,\n",
    "    final_activation=\"softmax\",\n",
    ").to(device)\n",
    "\n",
    "state_dict = torch.load(\"./models/Nseg\", map_location=device)\n",
    "Nseg.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_dict = {0: 'white',\n",
    "              1: 'black',\n",
    "              2: 'blue',\n",
    "            }\n",
    "cm = ListedColormap(color_dict.values())\n",
    "cbar_lims = (0,2)\n",
    "size = 5\n",
    "Nseg.eval()\n",
    "with torch.no_grad():\n",
    "    for input_sigma_C, output_seg_C in dataloaders[\"test_seg_C\"]:\n",
    "        input_seg_C = input_sigma_C[:,:1]\n",
    "        preds_Nseg_C = Nseg(input_seg_C.to(device))\n",
    "        \n",
    "        input_seg_C = input_seg_C.detach().cpu().numpy()\n",
    "        preds_Nseg_C = preds_Nseg_C.detach().cpu().numpy()[0]\n",
    "\n",
    "        segmented = np.zeros(preds_Nseg_C[0].shape)\n",
    "        segmented += np.array(preds_Nseg_C[1]>0.5)*1\n",
    "        segmented += np.array(preds_Nseg_C[2]>=0.5)*2\n",
    "\n",
    "        fig = plt.figure(figsize=(size, size/2), constrained_layout=True)\n",
    "        subfig = fig.subfigures(nrows=1, ncols=1, hspace=0.)\n",
    "        axes = subfig.subplots(nrows=1, ncols=2, gridspec_kw={'width_ratios': [1, 1]})\n",
    "\n",
    "\n",
    "        im_gs = sns.heatmap(input_seg_C[0,0], ax=axes[0], cmap='gray', cbar=False)\n",
    "        im_seg = sns.heatmap(segmented, ax=axes[1], cmap=cm, cbar=False, vmin=cbar_lims[0], vmax=cbar_lims[1])\n",
    "\n",
    "        for ax in axes:\n",
    "            ax.grid(False)\n",
    "            ax.axis('tight')\n",
    "            ax.set_xticks([])\n",
    "            ax.set_yticks([])\n",
    "            ax.set_aspect('equal')\n",
    "\n",
    "\n",
    "        for image in [im_gs, im_seg]:\n",
    "            image.invert_yaxis()\n",
    "            for _, spine in image.spines.items(): \n",
    "                spine.set_visible(True) \n",
    "                spine.set_linewidth(1) \n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nsigma = UNet(\n",
    "    n_channels=4,\n",
    "    n_output_channels=3,\n",
    "    initial_channels=32,\n",
    "    ndepth=5,\n",
    "    bilinear=False,\n",
    "    activation=\"elu\",\n",
    "    dropout_rate=None,\n",
    ").to(device)\n",
    "\n",
    "state_dict = torch.load(\"./models/Nsigma\", map_location=device)\n",
    "Nsigma.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nsigma.eval()\n",
    "titles = ['Prediction', 'Ground truth']\n",
    "components = [r'$\\sigma_{xx}$', r'$\\sigma_{xy}$', r'$\\sigma_{yy}$']\n",
    "size = 5\n",
    "with torch.no_grad():\n",
    "    for input_sigma_C, output_sigma_C in dataloaders['test_sigma_C']:\n",
    "        preds_sigma_C = Nsigma(input_sigma_C.to(device))\n",
    "\n",
    "        preds_sigma_C = preds_sigma_C.detach().cpu().numpy()\n",
    "        output_sigma_C = output_sigma_C.detach().cpu().numpy()\n",
    "        for i in range(3):\n",
    "            fig, axes = plt.subplots(1, 2, figsize=(size, size/2))\n",
    "\n",
    "            im_pred = sns.heatmap(\n",
    "                preds_sigma_C[0, i],\n",
    "                cmap='plasma',\n",
    "                ax=axes[0],\n",
    "            )\n",
    "            im_gt = sns.heatmap(\n",
    "                output_sigma_C[0, i],\n",
    "                cmap='plasma',\n",
    "                ax=axes[1],\n",
    "            )\n",
    "            \n",
    "            im_pred.invert_yaxis()\n",
    "            im_gt.invert_yaxis()\n",
    "\n",
    "            for c_ax, ax in enumerate(axes):\n",
    "                ax.axis(\"tight\")\n",
    "                ax.set_axis_off()\n",
    "                ax.set_aspect(\"equal\")\n",
    "                ax.set_title(titles[c_ax]+' '+components[i], fontsize=10)\n",
    "\n",
    "            plt.tight_layout(pad=0)\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
